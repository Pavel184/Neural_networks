{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Homework_lesson_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavel184/Neural_networks/blob/Homework_lesson_3/Homework_lesson_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9uRd98UFzPL"
      },
      "source": [
        "# Homework_lesson_3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3iOZn2wFzPQ"
      },
      "source": [
        "1. Постройте нейронную сеть(берем простую линейную сеть, которую разбирали на уроке: меняем число слоев, число нейронов , типы активации, тип оптимизатора)  на датасет from sklearn.datasets import load_boston. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xD9laMOgDJC3"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "#from tensorflow.keras.datasets import mnist\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "#from tensorflow.keras.utils import to_categorical\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBUSq3dWHUjF"
      },
      "source": [
        "# Загрузка датасета и разделение на train test\n",
        "X, y = load_boston(return_X_y=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, \n",
        "                                                    random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhUganN2RAJ9"
      },
      "source": [
        "# размер входных данных\n",
        "dim = X_train.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozb2tTqNIBzX"
      },
      "source": [
        "# Масштабирование данных\n",
        "mean = X_train.mean(axis=0)\n",
        "std = X_train.std(axis=0)\n",
        "X_train = (X_train - mean) / std\n",
        "X_test = (X_test - mean) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifss_YjQHXlS",
        "outputId": "e412ad3e-a28b-4d69-b177-f80554e4c627"
      },
      "source": [
        "# Построение модели\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(dim, ), activation='relu', name='dense_1'))\n",
        "model.add(Dense(64, activation='relu', name='dense_2'))\n",
        "model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               1792      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_output (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 10,113\n",
            "Trainable params: 10,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJYvFw7jHXoa"
      },
      "source": [
        "# Обучение модели\n",
        "hist = model.fit(X_train, y_train, epochs=100, validation_split=0.05, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "ttbfMAQJHXrZ",
        "outputId": "235d84b7-ee46-427c-95ee-f1ec8c697259"
      },
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scattergl(y=hist.history['loss'],\n",
        "                    name='Train'))\n",
        "fig.add_trace(go.Scattergl(y=hist.history['val_loss'],\n",
        "                    name='Valid'))\n",
        "fig.update_layout(height=500, width=700,\n",
        "                  xaxis_title='Epoch',\n",
        "                  yaxis_title='Loss')\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"1a8209ef-aa61-48be-b905-ba0b026a6dc6\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"1a8209ef-aa61-48be-b905-ba0b026a6dc6\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '1a8209ef-aa61-48be-b905-ba0b026a6dc6',\n",
              "                        [{\"name\": \"Train\", \"type\": \"scattergl\", \"y\": [594.805419921875, 537.8709716796875, 463.9189147949219, 366.10845947265625, 248.40841674804688, 148.4162139892578, 88.09483337402344, 62.78601837158203, 47.024070739746094, 34.62546920776367, 28.711435317993164, 25.415878295898438, 23.34647560119629, 22.137479782104492, 20.934240341186523, 19.904022216796875, 19.127119064331055, 18.42191505432129, 17.796621322631836, 17.032995223999023, 16.504711151123047, 16.15281105041504, 15.571900367736816, 15.035004615783691, 14.797897338867188, 14.469477653503418, 14.022398948669434, 13.667378425598145, 13.442172050476074, 13.16911506652832, 12.862176895141602, 12.860662460327148, 12.492548942565918, 12.308499336242676, 12.094850540161133, 12.007230758666992, 11.982749938964844, 11.702263832092285, 11.818046569824219, 11.277705192565918, 12.397398948669434, 12.33188533782959, 11.747721672058105, 11.448271751403809, 11.329849243164062, 10.655498504638672, 10.514965057373047, 10.372562408447266, 10.252727508544922, 11.020112991333008, 10.828900337219238, 10.525506019592285, 10.630702018737793, 10.397282600402832, 10.18743896484375, 9.698823928833008, 9.58726692199707, 9.67452335357666, 9.800524711608887, 9.370542526245117, 9.292359352111816, 9.354365348815918, 9.21142578125, 9.315376281738281, 9.025766372680664, 9.154351234436035, 8.97214126586914, 8.89734935760498, 8.71234130859375, 8.732281684875488, 8.518038749694824, 8.803196907043457, 8.545358657836914, 8.611332893371582, 8.311702728271484, 8.37491512298584, 8.423367500305176, 8.6212739944458, 8.620501518249512, 8.232030868530273, 8.198551177978516, 8.131409645080566, 8.048839569091797, 7.962240219116211, 8.196575164794922, 7.892335414886475, 7.885815143585205, 7.752096652984619, 7.725318908691406, 7.632335662841797, 7.505809307098389, 7.656487941741943, 7.542211532592773, 7.600313186645508, 7.762420654296875, 7.466006755828857, 7.347996711730957, 7.292113304138184, 7.226730823516846, 7.222853183746338]}, {\"name\": \"Valid\", \"type\": \"scattergl\", \"y\": [515.339599609375, 451.3223876953125, 365.7319030761719, 262.6766052246094, 163.2830047607422, 97.19600677490234, 81.26854705810547, 76.6181411743164, 68.5500259399414, 64.46581268310547, 63.128440856933594, 61.98005294799805, 62.561920166015625, 60.756248474121094, 59.528175354003906, 58.772239685058594, 57.49448013305664, 57.388065338134766, 55.362972259521484, 55.19390869140625, 56.25584411621094, 54.89510726928711, 52.62213134765625, 50.32383728027344, 49.44221878051758, 48.998985290527344, 49.94052505493164, 48.753997802734375, 48.246551513671875, 48.292701721191406, 46.734588623046875, 44.5657844543457, 45.295074462890625, 42.68492126464844, 44.21665954589844, 40.553829193115234, 42.507904052734375, 48.71553421020508, 45.49397659301758, 45.187828063964844, 54.662715911865234, 52.90242385864258, 46.98781204223633, 43.68883514404297, 45.17606735229492, 43.25653839111328, 41.83211135864258, 42.17104721069336, 40.364585876464844, 31.042924880981445, 32.408241271972656, 29.600204467773438, 31.936201095581055, 35.31587600708008, 35.2900390625, 33.56332015991211, 34.27619171142578, 37.69385528564453, 39.4278564453125, 36.20487976074219, 36.601566314697266, 37.99657440185547, 38.08320617675781, 36.410560607910156, 34.97993087768555, 34.656402587890625, 36.190677642822266, 37.696956634521484, 37.83534622192383, 37.61804962158203, 34.49589538574219, 35.080787658691406, 35.361324310302734, 35.412540435791016, 35.20586013793945, 34.5019645690918, 30.152013778686523, 30.558320999145508, 30.470218658447266, 33.334041595458984, 32.213592529296875, 35.17744445800781, 33.606536865234375, 32.04177474975586, 33.23881149291992, 34.40332794189453, 32.848575592041016, 33.075347900390625, 33.05813980102539, 32.805179595947266, 33.03861618041992, 33.73579025268555, 32.82754898071289, 33.121795654296875, 31.90639305114746, 32.64590072631836, 32.783626556396484, 30.687328338623047, 32.18065643310547, 31.29509735107422]}],\n",
              "                        {\"height\": 500, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 700, \"xaxis\": {\"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"title\": {\"text\": \"Loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1a8209ef-aa61-48be-b905-ba0b026a6dc6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7da5eDc5HXvq",
        "outputId": "75295c74-4e1a-4fc7-ac0e-3452cdbf6134"
      },
      "source": [
        "# Метрики\n",
        "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
        "print('MSE на тестовых данных: ', mse_nn)\n",
        "print('MAE на тестовых данных: ', mae_nn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 10.7036 - mae: 2.1747\n",
            "MSE на тестовых данных:  10.703579902648926\n",
            "MAE на тестовых данных:  2.174665689468384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp1QxTS-TMWh"
      },
      "source": [
        "2. Измените функцию потерь и метрику для этой задачи. Постройте 10-15 вариантов и сведите результаты их работы в таблицу  Опишите, какого результата вы добились от нейросети? Что помогло вам улучшить ее точность?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYE3MwNYHyRU"
      },
      "source": [
        "# Таблица результатов\n",
        "models_results = {\n",
        "    'approach': [],\n",
        "    'activation_func': [],\n",
        "    'metrics': [],\n",
        "    'neurons_number': [],\n",
        "    'epochs_numb': [],\n",
        "    'type_of_loss': [],\n",
        "    'optimizer': [],\n",
        "    'MSE_test': [],\n",
        "    'MAE_test': []\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oglKNuY0XaY-"
      },
      "source": [
        "# Модели с разными параметрами\n",
        "epochs_numb = [100, 200, 500]\n",
        "loss_list = ['mean_squared_error', 'mean_absolute_error', \n",
        "        'mean_absolute_percentage_error', 'mean_squared_logarithmic_error',\n",
        "        'cosine_similarity']\n",
        "optimizer_list = ['adam', 'Nadam', 'SGD', 'RMSprop', 'Ftrl', 'Adamax', \n",
        "                  'Adagrad', 'Adadelta']\n",
        "neurons_numb = [[64,32], [128,64], [256,128], [512, 256]]\n",
        "metrics_list = ['mae', 'mse']\n",
        "act_fn_list = ['relu', 'sigmoid', 'tanh', 'elu']\n",
        "for epochs in epochs_numb:\n",
        "  for loss in loss_list:\n",
        "    for optimizer in optimizer_list:\n",
        "      for n_numb in neurons_numb:\n",
        "        for metrics in metrics_list:\n",
        "          for activation in act_fn_list:\n",
        "            model_1 = Sequential()\n",
        "            model_1.add(Dense(n_numb[0], input_shape=(dim, ), activation='relu', name='dense_1'))\n",
        "            model_1.add(Dense(n_numb[1], activation=activation, name='dense_2'))\n",
        "            model_1.add(Dense(1, activation='linear', name='dense_output'))\n",
        "            model_1.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "            model_1.fit(X_train, y_train, epochs=epochs, validation_split=0.05, verbose=0)\n",
        "\n",
        "            mse_nn, mae_nn = model_1.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "            models_results['approach'].append('2 layers model')\n",
        "            models_results['activation_func'].append(activation)\n",
        "            models_results['metrics'].append(metrics)\n",
        "            models_results['neurons_number'].append(n_numb)\n",
        "            models_results['epochs_numb'].append(epochs)\n",
        "            models_results['type_of_loss'].append(loss)\n",
        "            models_results['optimizer'].append(optimizer)\n",
        "            models_results['MSE_test'].append(mse_nn)\n",
        "            models_results['MAE_test'].append(mae_nn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W13eWlBN5yJF",
        "outputId": "9803a163-8cab-4dfb-d6ad-1c043e7df6f6"
      },
      "source": [
        "# Итоговая таблица\n",
        "df_1 = pd.DataFrame(data=models_results).sort_values('MSE_test', ascending=True)\n",
        "df_1.head(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>approach</th>\n",
              "      <th>activation_func</th>\n",
              "      <th>metrics</th>\n",
              "      <th>neurons_number</th>\n",
              "      <th>epochs_numb</th>\n",
              "      <th>type_of_loss</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>MSE_test</th>\n",
              "      <th>MAE_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2455</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>elu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>200</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Ftrl</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>544.085510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1229</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mse</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>100</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Adagrad</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>511.950226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mse</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>100</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Adagrad</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>525.993164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1241</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mae</td>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>100</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Adagrad</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>20.983261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1265</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mae</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>100</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Adadelta</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>21.536509</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mse</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>200</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>485.905975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>200</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>383.149445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>elu</td>\n",
              "      <td>mae</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>200</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>16.566603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mae</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>200</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>17.194485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mae</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>200</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>19.700150</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            approach activation_func metrics neurons_number  epochs_numb  \\\n",
              "2455  2 layers model             elu     mse     [256, 128]          200   \n",
              "1229  2 layers model         sigmoid     mse      [128, 64]          100   \n",
              "1237  2 layers model         sigmoid     mse     [256, 128]          100   \n",
              "1241  2 layers model         sigmoid     mae     [512, 256]          100   \n",
              "1265  2 layers model         sigmoid     mae     [256, 128]          100   \n",
              "...              ...             ...     ...            ...          ...   \n",
              "2477  2 layers model         sigmoid     mse      [128, 64]          200   \n",
              "2476  2 layers model            relu     mse      [128, 64]          200   \n",
              "2475  2 layers model             elu     mae      [128, 64]          200   \n",
              "2474  2 layers model            tanh     mae      [128, 64]          200   \n",
              "2473  2 layers model         sigmoid     mae      [128, 64]          200   \n",
              "\n",
              "           type_of_loss optimizer  MSE_test    MAE_test  \n",
              "2455  cosine_similarity      Ftrl      -1.0  544.085510  \n",
              "1229  cosine_similarity   Adagrad      -1.0  511.950226  \n",
              "1237  cosine_similarity   Adagrad      -1.0  525.993164  \n",
              "1241  cosine_similarity   Adagrad      -1.0   20.983261  \n",
              "1265  cosine_similarity  Adadelta      -1.0   21.536509  \n",
              "...                 ...       ...       ...         ...  \n",
              "2477  cosine_similarity    Adamax      -1.0  485.905975  \n",
              "2476  cosine_similarity    Adamax      -1.0  383.149445  \n",
              "2475  cosine_similarity    Adamax      -1.0   16.566603  \n",
              "2474  cosine_similarity    Adamax      -1.0   17.194485  \n",
              "2473  cosine_similarity    Adamax      -1.0   19.700150  \n",
              "\n",
              "[100 rows x 9 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKB6INdA5yJG",
        "outputId": "9f124007-3884-4845-c266-1f1df91b0fd4"
      },
      "source": [
        "# Убираем отрецательные значения\n",
        "df_2 =df_1.drop(df_1[df_1.MSE_test < 0].index)\n",
        "df_2.head(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>approach</th>\n",
              "      <th>activation_func</th>\n",
              "      <th>metrics</th>\n",
              "      <th>neurons_number</th>\n",
              "      <th>epochs_numb</th>\n",
              "      <th>type_of_loss</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>MSE_test</th>\n",
              "      <th>MAE_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1103</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>elu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>100</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.005988</td>\n",
              "      <td>540.036926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3350</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mse</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.017484</td>\n",
              "      <td>9.499741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2514</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mae</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>200</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>Adagrad</td>\n",
              "      <td>0.017964</td>\n",
              "      <td>21.621441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2370</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mae</td>\n",
              "      <td>[64, 32]</td>\n",
              "      <td>200</td>\n",
              "      <td>cosine_similarity</td>\n",
              "      <td>SGD</td>\n",
              "      <td>0.017964</td>\n",
              "      <td>21.694885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3433</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mae</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.018873</td>\n",
              "      <td>2.121380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3378</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mae</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>0.019159</td>\n",
              "      <td>2.161700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2153</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mae</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>200</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.020121</td>\n",
              "      <td>2.159405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3424</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mae</td>\n",
              "      <td>[64, 32]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.020266</td>\n",
              "      <td>2.083420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3332</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[64, 32]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.020427</td>\n",
              "      <td>10.281829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3346</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mae</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.020571</td>\n",
              "      <td>2.165648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2154</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mae</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>200</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.020614</td>\n",
              "      <td>2.281359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>868</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[64, 32]</td>\n",
              "      <td>100</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.020758</td>\n",
              "      <td>10.204733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3382</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mse</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>0.020989</td>\n",
              "      <td>10.266685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3343</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>elu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[128, 64]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.021030</td>\n",
              "      <td>9.943022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2148</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[64, 32]</td>\n",
              "      <td>200</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.021154</td>\n",
              "      <td>10.360040</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2110</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mse</td>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>200</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>0.021160</td>\n",
              "      <td>11.826797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2104</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mae</td>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>200</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>0.021344</td>\n",
              "      <td>2.067674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3519</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>elu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>0.021345</td>\n",
              "      <td>10.316448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3516</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>0.021365</td>\n",
              "      <td>10.301834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2144</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mae</td>\n",
              "      <td>[64, 32]</td>\n",
              "      <td>200</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.021378</td>\n",
              "      <td>2.098626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2078</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mse</td>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>200</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.021453</td>\n",
              "      <td>11.660480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3381</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>sigmoid</td>\n",
              "      <td>mse</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>Nadam</td>\n",
              "      <td>0.021464</td>\n",
              "      <td>12.325547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>871</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>elu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[64, 32]</td>\n",
              "      <td>100</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.021679</td>\n",
              "      <td>11.218215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3515</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>elu</td>\n",
              "      <td>mae</td>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>0.021698</td>\n",
              "      <td>2.113559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>864</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mae</td>\n",
              "      <td>[64, 32]</td>\n",
              "      <td>100</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.021752</td>\n",
              "      <td>2.185661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2068</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mse</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>200</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.021758</td>\n",
              "      <td>10.559499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3354</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mae</td>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.021759</td>\n",
              "      <td>2.205339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3518</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>tanh</td>\n",
              "      <td>mse</td>\n",
              "      <td>[512, 256]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>0.021761</td>\n",
              "      <td>11.026632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3504</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mae</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>500</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>0.021764</td>\n",
              "      <td>2.104473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2064</th>\n",
              "      <td>2 layers model</td>\n",
              "      <td>relu</td>\n",
              "      <td>mae</td>\n",
              "      <td>[256, 128]</td>\n",
              "      <td>200</td>\n",
              "      <td>mean_squared_logarithmic_error</td>\n",
              "      <td>adam</td>\n",
              "      <td>0.021820</td>\n",
              "      <td>2.141929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            approach activation_func metrics neurons_number  epochs_numb  \\\n",
              "1103  2 layers model             elu     mse      [128, 64]          100   \n",
              "3350  2 layers model            tanh     mse     [256, 128]          500   \n",
              "2514  2 layers model            tanh     mae     [256, 128]          200   \n",
              "2370  2 layers model            tanh     mae       [64, 32]          200   \n",
              "3433  2 layers model         sigmoid     mae      [128, 64]          500   \n",
              "3378  2 layers model            tanh     mae     [256, 128]          500   \n",
              "2153  2 layers model         sigmoid     mae      [128, 64]          200   \n",
              "3424  2 layers model            relu     mae       [64, 32]          500   \n",
              "3332  2 layers model            relu     mse       [64, 32]          500   \n",
              "3346  2 layers model            tanh     mae     [256, 128]          500   \n",
              "2154  2 layers model            tanh     mae      [128, 64]          200   \n",
              "868   2 layers model            relu     mse       [64, 32]          100   \n",
              "3382  2 layers model            tanh     mse     [256, 128]          500   \n",
              "3343  2 layers model             elu     mse      [128, 64]          500   \n",
              "2148  2 layers model            relu     mse       [64, 32]          200   \n",
              "2110  2 layers model            tanh     mse     [512, 256]          200   \n",
              "2104  2 layers model            relu     mae     [512, 256]          200   \n",
              "3519  2 layers model             elu     mse     [512, 256]          500   \n",
              "3516  2 layers model            relu     mse     [512, 256]          500   \n",
              "2144  2 layers model            relu     mae       [64, 32]          200   \n",
              "2078  2 layers model            tanh     mse     [512, 256]          200   \n",
              "3381  2 layers model         sigmoid     mse     [256, 128]          500   \n",
              "871   2 layers model             elu     mse       [64, 32]          100   \n",
              "3515  2 layers model             elu     mae     [512, 256]          500   \n",
              "864   2 layers model            relu     mae       [64, 32]          100   \n",
              "2068  2 layers model            relu     mse     [256, 128]          200   \n",
              "3354  2 layers model            tanh     mae     [512, 256]          500   \n",
              "3518  2 layers model            tanh     mse     [512, 256]          500   \n",
              "3504  2 layers model            relu     mae     [256, 128]          500   \n",
              "2064  2 layers model            relu     mae     [256, 128]          200   \n",
              "\n",
              "                        type_of_loss optimizer  MSE_test    MAE_test  \n",
              "1103               cosine_similarity       SGD  0.005988  540.036926  \n",
              "3350  mean_squared_logarithmic_error      adam  0.017484    9.499741  \n",
              "2514               cosine_similarity   Adagrad  0.017964   21.621441  \n",
              "2370               cosine_similarity       SGD  0.017964   21.694885  \n",
              "3433  mean_squared_logarithmic_error   RMSprop  0.018873    2.121380  \n",
              "3378  mean_squared_logarithmic_error     Nadam  0.019159    2.161700  \n",
              "2153  mean_squared_logarithmic_error   RMSprop  0.020121    2.159405  \n",
              "3424  mean_squared_logarithmic_error   RMSprop  0.020266    2.083420  \n",
              "3332  mean_squared_logarithmic_error      adam  0.020427   10.281829  \n",
              "3346  mean_squared_logarithmic_error      adam  0.020571    2.165648  \n",
              "2154  mean_squared_logarithmic_error   RMSprop  0.020614    2.281359  \n",
              "868   mean_squared_logarithmic_error   RMSprop  0.020758   10.204733  \n",
              "3382  mean_squared_logarithmic_error     Nadam  0.020989   10.266685  \n",
              "3343  mean_squared_logarithmic_error      adam  0.021030    9.943022  \n",
              "2148  mean_squared_logarithmic_error   RMSprop  0.021154   10.360040  \n",
              "2110  mean_squared_logarithmic_error     Nadam  0.021160   11.826797  \n",
              "2104  mean_squared_logarithmic_error     Nadam  0.021344    2.067674  \n",
              "3519  mean_squared_logarithmic_error    Adamax  0.021345   10.316448  \n",
              "3516  mean_squared_logarithmic_error    Adamax  0.021365   10.301834  \n",
              "2144  mean_squared_logarithmic_error   RMSprop  0.021378    2.098626  \n",
              "2078  mean_squared_logarithmic_error      adam  0.021453   11.660480  \n",
              "3381  mean_squared_logarithmic_error     Nadam  0.021464   12.325547  \n",
              "871   mean_squared_logarithmic_error   RMSprop  0.021679   11.218215  \n",
              "3515  mean_squared_logarithmic_error    Adamax  0.021698    2.113559  \n",
              "864   mean_squared_logarithmic_error   RMSprop  0.021752    2.185661  \n",
              "2068  mean_squared_logarithmic_error      adam  0.021758   10.559499  \n",
              "3354  mean_squared_logarithmic_error      adam  0.021759    2.205339  \n",
              "3518  mean_squared_logarithmic_error    Adamax  0.021761   11.026632  \n",
              "3504  mean_squared_logarithmic_error    Adamax  0.021764    2.104473  \n",
              "2064  mean_squared_logarithmic_error      adam  0.021820    2.141929  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gCjP8Fb5yJG"
      },
      "source": [
        "Лучший результат MSE 0.018873 MAE 2.121380"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "id": "chlvcsMw5yJG",
        "outputId": "ffa56055-bb41-4807-ae7d-62c47c277396"
      },
      "source": [
        "# Построим модель наилучшего результата\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(dim, ), activation='sigmoid', name='dense_1'))\n",
        "model.add(Dense(64, activation='sigmoid', name='dense_2'))\n",
        "model.add(Dense(1, activation='linear', name='dense_output'))\n",
        "model.compile(optimizer='RMSprop', loss='mean_squared_logarithmic_error', metrics=['mae'])\n",
        "model.summary()\n",
        "# Обучение модели\n",
        "hist = model.fit(X_train, y_train, epochs=500, validation_split=0.05, verbose=0)\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scattergl(y=hist.history['loss'],\n",
        "                    name='Train'))\n",
        "fig.add_trace(go.Scattergl(y=hist.history['val_loss'],\n",
        "                    name='Valid'))\n",
        "fig.update_layout(height=500, width=700,\n",
        "                  xaxis_title='Epoch',\n",
        "                  yaxis_title='Loss')\n",
        "fig.show()\n",
        "# Метрики\n",
        "mse_nn, mae_nn = model.evaluate(X_test, y_test)\n",
        "print('MSE на тестовых данных: ', mse_nn)\n",
        "print('MAE на тестовых данных: ', mae_nn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               1792      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_output (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 10,113\n",
            "Trainable params: 10,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"edd2993a-a373-4f42-baec-b5c476612231\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"edd2993a-a373-4f42-baec-b5c476612231\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'edd2993a-a373-4f42-baec-b5c476612231',\n",
              "                        [{\"name\": \"Train\", \"type\": \"scattergl\", \"y\": [4.991918563842773, 2.9477460384368896, 2.203348398208618, 1.7754403352737427, 1.4730949401855469, 1.2668815851211548, 1.1010874509811401, 0.9688683748245239, 0.8680018186569214, 0.7812149524688721, 0.7079170942306519, 0.6445784568786621, 0.5865867137908936, 0.5367936491966248, 0.4951002299785614, 0.45574668049812317, 0.417677640914917, 0.3868905305862427, 0.3575763702392578, 0.3318203091621399, 0.3076252043247223, 0.28532811999320984, 0.26803454756736755, 0.24919524788856506, 0.2324182540178299, 0.2154187262058258, 0.20062364637851715, 0.18660715222358704, 0.17358705401420593, 0.16092489659786224, 0.15047022700309753, 0.14122897386550903, 0.13202913105487823, 0.12401998043060303, 0.11706986278295517, 0.11101312935352325, 0.10545957833528519, 0.09985678642988205, 0.09532342106103897, 0.09063398838043213, 0.08676625788211823, 0.08275067061185837, 0.0790097713470459, 0.07646732032299042, 0.07374022156000137, 0.07154815644025803, 0.07010478526353836, 0.06845930963754654, 0.06713143736124039, 0.06576333194971085, 0.06419939547777176, 0.06314113736152649, 0.0620693601667881, 0.060935575515031815, 0.0597400888800621, 0.05886537954211235, 0.057962801307439804, 0.05722731351852417, 0.05653730779886246, 0.05605864152312279, 0.055566564202308655, 0.05462731793522835, 0.0538267157971859, 0.05338707193732262, 0.05266820266842842, 0.05226733535528183, 0.05187893658876419, 0.050889454782009125, 0.050433199852705, 0.05029813572764397, 0.04977494478225708, 0.04908513277769089, 0.04795331507921219, 0.04950534552335739, 0.04798697680234909, 0.04715527966618538, 0.047058071941137314, 0.04682575911283493, 0.04572764039039612, 0.04612228274345398, 0.04509608820080757, 0.04462103545665741, 0.044084999710321426, 0.04411313682794571, 0.043809644877910614, 0.04315576329827309, 0.04342982545495033, 0.0426369346678257, 0.04189811274409294, 0.041595105081796646, 0.04128829017281532, 0.041327379643917084, 0.040622372180223465, 0.04022712633013725, 0.03972381353378296, 0.039381492882966995, 0.03909572958946228, 0.03845549002289772, 0.03807346150279045, 0.03784686699509621, 0.03752000629901886, 0.03701112046837807, 0.036433156579732895, 0.03639692813158035, 0.03597281873226166, 0.03592989966273308, 0.03606058657169342, 0.034925054758787155, 0.0351286306977272, 0.03469998389482498, 0.034402478486299515, 0.033964816480875015, 0.033522263169288635, 0.0336628332734108, 0.032875798642635345, 0.03249257802963257, 0.03234069421887398, 0.0314326249063015, 0.03163278102874756, 0.03167784586548805, 0.031490907073020935, 0.0311279296875, 0.03035742975771427, 0.030216190963983536, 0.03007098101079464, 0.029606712982058525, 0.029252149164676666, 0.028967199847102165, 0.029040629044175148, 0.028568940237164497, 0.02821326069533825, 0.02823473885655403, 0.027994658797979355, 0.027671106159687042, 0.027263175696134567, 0.026889745146036148, 0.0277140811085701, 0.026393786072731018, 0.026641493663191795, 0.02622031606733799, 0.026026932522654533, 0.02588007040321827, 0.02538282424211502, 0.02537030167877674, 0.025639379397034645, 0.02472834475338459, 0.02469060942530632, 0.024583090096712112, 0.02451413683593273, 0.024175316095352173, 0.024007825180888176, 0.02354801446199417, 0.023811228573322296, 0.023649265989661217, 0.023535147309303284, 0.023145390674471855, 0.023201722651720047, 0.023143894970417023, 0.02265494130551815, 0.022588340565562248, 0.022311853244900703, 0.022431807592511177, 0.02222827821969986, 0.022179674357175827, 0.022447608411312103, 0.02233237586915493, 0.021732697263360023, 0.021913014352321625, 0.021704290062189102, 0.02148672752082348, 0.021451512351632118, 0.021449198946356773, 0.021168451756238937, 0.021717224270105362, 0.021121684461832047, 0.021068936213850975, 0.020913859829306602, 0.020986085757613182, 0.020955009385943413, 0.020717643201351166, 0.020944779738783836, 0.020333295688033104, 0.021120358258485794, 0.020041799172759056, 0.020155679434537888, 0.02082953415811062, 0.020595990121364594, 0.020032132044434547, 0.02005423605442047, 0.020222410559654236, 0.020450321957468987, 0.019855910912156105, 0.02070865035057068, 0.02036958932876587, 0.0196735467761755, 0.01990092545747757, 0.02034880220890045, 0.019449295476078987, 0.01929573155939579, 0.01987297274172306, 0.019453050568699837, 0.01942158117890358, 0.0195096954703331, 0.020067883655428886, 0.019487204030156136, 0.019220935180783272, 0.019567102193832397, 0.019242018461227417, 0.019415510818362236, 0.01932212896645069, 0.01915237121284008, 0.019359154626727104, 0.0192989744246006, 0.019633470103144646, 0.018739501014351845, 0.018994636833667755, 0.019093329086899757, 0.01927267760038376, 0.018642175942659378, 0.01912519335746765, 0.01852152869105339, 0.01902880147099495, 0.017828432843089104, 0.02039620652794838, 0.019318146631121635, 0.01830916665494442, 0.0184792373329401, 0.0191181767731905, 0.01857643574476242, 0.01812845841050148, 0.018733639270067215, 0.0182949211448431, 0.018165770918130875, 0.018603505566716194, 0.018391285091638565, 0.018235687166452408, 0.018241936340928078, 0.017828308045864105, 0.017875205725431442, 0.018234530463814735, 0.01820375770330429, 0.018092170357704163, 0.018740788102149963, 0.017864814028143883, 0.01775681972503662, 0.017888059839606285, 0.017523661255836487, 0.018869303166866302, 0.017488574609160423, 0.01750161498785019, 0.01893806830048561, 0.017746111378073692, 0.017443211749196053, 0.01760401576757431, 0.01771380752325058, 0.017710993066430092, 0.017477238550782204, 0.017297441139817238, 0.01720459759235382, 0.017324725165963173, 0.017516011372208595, 0.01750594936311245, 0.01687605120241642, 0.01758708991110325, 0.01747976988554001, 0.01701241172850132, 0.017228396609425545, 0.01708066463470459, 0.017766190692782402, 0.017910709604620934, 0.016853712499141693, 0.01709352806210518, 0.01707305759191513, 0.016941247507929802, 0.017336824908852577, 0.016842074692249298, 0.017213068902492523, 0.017009936273097992, 0.01693812943994999, 0.017246084287762642, 0.016515694558620453, 0.01707826554775238, 0.017036322504281998, 0.01681354083120823, 0.017240632325410843, 0.016716549172997475, 0.016419455409049988, 0.016454260796308517, 0.01721455343067646, 0.01622813567519188, 0.016576532274484634, 0.016598068177700043, 0.016544973477721214, 0.016398238018155098, 0.016868004575371742, 0.016086526215076447, 0.0164054986089468, 0.016952034085989, 0.016178186982870102, 0.016629265621304512, 0.01631852239370346, 0.01641547493636608, 0.01622246578335762, 0.016406193375587463, 0.01652013696730137, 0.016243059188127518, 0.016342276707291603, 0.017237642779946327, 0.016128238290548325, 0.016033247113227844, 0.01633257046341896, 0.01610899530351162, 0.016262952238321304, 0.016352668404579163, 0.015771694481372833, 0.016016703099012375, 0.01573096215724945, 0.0157021377235651, 0.015856580808758736, 0.01573076844215393, 0.015645582228899002, 0.01573093608021736, 0.015628498047590256, 0.015973079949617386, 0.015730557963252068, 0.01602298952639103, 0.01557063776999712, 0.015669183805584908, 0.016273360699415207, 0.015707504004240036, 0.015546421520411968, 0.015453195199370384, 0.016676170751452446, 0.015584252774715424, 0.015515287406742573, 0.015854191035032272, 0.015535535290837288, 0.01566089689731598, 0.015200772322714329, 0.016032693907618523, 0.0153579106554389, 0.015671895816922188, 0.015331395901739597, 0.015735210850834846, 0.015023482963442802, 0.015303518623113632, 0.015187133103609085, 0.015532678924500942, 0.015390303917229176, 0.014971869066357613, 0.015180706046521664, 0.015233905985951424, 0.015271823853254318, 0.015369994565844536, 0.01488801371306181, 0.014863862656056881, 0.015048240311443806, 0.015301932580769062, 0.015301167964935303, 0.01485361997038126, 0.014786028303205967, 0.01514124870300293, 0.014905635267496109, 0.014928004704415798, 0.014819464646279812, 0.014630197547376156, 0.014928207732737064, 0.014669431373476982, 0.01480527501553297, 0.01496429368853569, 0.015008045360445976, 0.01480718981474638, 0.01427468191832304, 0.014741122722625732, 0.014822853729128838, 0.014723921194672585, 0.015296672470867634, 0.01431799866259098, 0.015301413834095001, 0.014583781361579895, 0.014509076252579689, 0.014530833810567856, 0.01488419622182846, 0.014359120279550552, 0.014305230230093002, 0.01451026275753975, 0.014711103402078152, 0.014368430711328983, 0.014799527823925018, 0.014017478562891483, 0.01427431870251894, 0.013967475853860378, 0.014394446276128292, 0.014484209939837456, 0.014305561780929565, 0.014294441789388657, 0.014135275036096573, 0.014090222306549549, 0.014061120338737965, 0.014348270371556282, 0.014006998389959335, 0.014429383911192417, 0.014378615655004978, 0.014042852446436882, 0.014045442454516888, 0.014248857274651527, 0.01439695805311203, 0.013646312057971954, 0.014532914385199547, 0.013786558993160725, 0.013613341376185417, 0.013883639127016068, 0.01370354276150465, 0.015770699828863144, 0.014083247631788254, 0.013752639293670654, 0.013683600351214409, 0.014063290320336819, 0.013848137110471725, 0.014395643956959248, 0.014352294616401196, 0.013595123775303364, 0.01413755863904953, 0.013774274848401546, 0.01404646597802639, 0.013774611055850983, 0.01415285561233759, 0.013441040180623531, 0.01353781670331955, 0.01350309420377016, 0.013998227193951607, 0.013692762702703476, 0.013460563495755196, 0.01350939180701971, 0.013398858718574047, 0.013774418272078037, 0.013731710612773895, 0.013791176490485668, 0.013524492271244526, 0.013422190211713314, 0.013708382844924927, 0.013231064192950726, 0.013441507704555988, 0.013670515269041061, 0.013250554911792278, 0.013693290762603283, 0.013335797935724258, 0.013401683419942856, 0.013594936579465866, 0.01360312569886446, 0.013628163374960423, 0.013334262184798717, 0.013534517958760262, 0.01349655445665121, 0.013038004748523235, 0.013458600267767906, 0.013103825971484184, 0.01397587638348341, 0.013509050942957401, 0.013287563808262348, 0.013056764379143715, 0.013352860696613789, 0.013125873170793056, 0.013286322355270386, 0.013219190761446953, 0.013294920325279236, 0.01295462902635336, 0.013463698327541351, 0.01334661990404129, 0.01319807767868042, 0.012949617579579353, 0.013144769705832005, 0.01305308286100626, 0.013143464922904968, 0.01315987203270197, 0.013197858817875385, 0.013410350307822227, 0.013022033497691154, 0.01302303746342659, 0.013373182155191898, 0.012579072266817093, 0.012856932356953621, 0.013030653819441795, 0.013017669320106506, 0.01288695354014635, 0.012846788391470909, 0.012796344235539436, 0.01294860802590847, 0.012919476255774498, 0.013663651421666145, 0.012784368358552456, 0.012594097293913364, 0.013045180588960648, 0.012807855382561684, 0.012884290888905525, 0.012954847887158394, 0.012527957558631897, 0.012630191631615162, 0.012672961689531803, 0.01276393886655569]}, {\"name\": \"Valid\", \"type\": \"scattergl\", \"y\": [3.2826175689697266, 2.339076519012451, 1.8437728881835938, 1.4999209642410278, 1.274106740951538, 1.0910539627075195, 0.945310115814209, 0.8381115794181824, 0.7447599768638611, 0.6676095724105835, 0.6010117530822754, 0.5404041409492493, 0.48819872736930847, 0.4469453692436218, 0.4070155620574951, 0.36750444769859314, 0.33694955706596375, 0.3071385324001312, 0.2814299166202545, 0.25737249851226807, 0.235335573554039, 0.21955251693725586, 0.2023160308599472, 0.18775641918182373, 0.17399193346500397, 0.16357417404651642, 0.15599916875362396, 0.14512237906455994, 0.1365329474210739, 0.1305752396583557, 0.1275433748960495, 0.12072526663541794, 0.11493898183107376, 0.10902584344148636, 0.10468675196170807, 0.10372989624738693, 0.1010548546910286, 0.10245241969823837, 0.10122013837099075, 0.10368380695581436, 0.09969765692949295, 0.09964604675769806, 0.09808360785245895, 0.09802025556564331, 0.1009993851184845, 0.10075589269399643, 0.09928946942090988, 0.09905111789703369, 0.0976388081908226, 0.09620458632707596, 0.0954011082649231, 0.09284919500350952, 0.09401371330022812, 0.0904359295964241, 0.08892244100570679, 0.08921004086732864, 0.09322146326303482, 0.09422360360622406, 0.08921438455581665, 0.08825522661209106, 0.08869093656539917, 0.08959440886974335, 0.08985833823680878, 0.09100565314292908, 0.08876004070043564, 0.08946479111909866, 0.09925033897161484, 0.09514690935611725, 0.10322917252779007, 0.09846808016300201, 0.0982000082731247, 0.10939723998308182, 0.09170164167881012, 0.10289568454027176, 0.10549303144216537, 0.10107147693634033, 0.11186055839061737, 0.10014894604682922, 0.11292414367198944, 0.10657712817192078, 0.10718362033367157, 0.10353752970695496, 0.11296429485082626, 0.12026748806238174, 0.10488826036453247, 0.1200050339102745, 0.10584533214569092, 0.10303632915019989, 0.10764088481664658, 0.11451713740825653, 0.12106839567422867, 0.11314994096755981, 0.09943407028913498, 0.10371672362089157, 0.10861163586378098, 0.10752590745687485, 0.10553450882434845, 0.10015550255775452, 0.10767946392297745, 0.10028469562530518, 0.10166444629430771, 0.10499445348978043, 0.09483113139867783, 0.10208996385335922, 0.09771130234003067, 0.11408776789903641, 0.10136546939611435, 0.09801536798477173, 0.10310955345630646, 0.08825679123401642, 0.09443387389183044, 0.08970233798027039, 0.09616971760988235, 0.08952747285366058, 0.09587221592664719, 0.09541073441505432, 0.09143242239952087, 0.08528418838977814, 0.08363106846809387, 0.09237736463546753, 0.09139424562454224, 0.08659792691469193, 0.07978398352861404, 0.08152729272842407, 0.07827696949243546, 0.08234072476625443, 0.0792897492647171, 0.07990408688783646, 0.07950081676244736, 0.08327322453260422, 0.08296724408864975, 0.07972943782806396, 0.08048723638057709, 0.08430282771587372, 0.08003847301006317, 0.07875674962997437, 0.07372025400400162, 0.07815995812416077, 0.0755346268415451, 0.07500220835208893, 0.0715145468711853, 0.07369867712259293, 0.0795745924115181, 0.07430532574653625, 0.07155738025903702, 0.07129013538360596, 0.07127512246370316, 0.07549133896827698, 0.0705028623342514, 0.06880887597799301, 0.07211694866418839, 0.07134594023227692, 0.07100608199834824, 0.06989040970802307, 0.0709415078163147, 0.06600387394428253, 0.06685587763786316, 0.06874769926071167, 0.06514065712690353, 0.07364064455032349, 0.06643947213888168, 0.06888746470212936, 0.06360901892185211, 0.06611079722642899, 0.07544028759002686, 0.06130342558026314, 0.06749901175498962, 0.06690378487110138, 0.06421372294425964, 0.0654207319021225, 0.06502293795347214, 0.07004670798778534, 0.061219602823257446, 0.0621974803507328, 0.06091209873557091, 0.06039470061659813, 0.06572103500366211, 0.06573832035064697, 0.060405563563108444, 0.0588013157248497, 0.06079961359500885, 0.06235140934586525, 0.06626379489898682, 0.06343289464712143, 0.07449965924024582, 0.06322053074836731, 0.06147266924381256, 0.0614936500787735, 0.06620946526527405, 0.05910204350948334, 0.060067035257816315, 0.055839117616415024, 0.055616751313209534, 0.06040901318192482, 0.06477315723896027, 0.05707242339849472, 0.06430979073047638, 0.06579754501581192, 0.06336644291877747, 0.07028040289878845, 0.05915103107690811, 0.06712023168802261, 0.06218934804201126, 0.06585262715816498, 0.058364227414131165, 0.06799513101577759, 0.06404237449169159, 0.06566903740167618, 0.07087422907352448, 0.05916142463684082, 0.06313257664442062, 0.05832136422395706, 0.05444200709462166, 0.05964704975485802, 0.06024560332298279, 0.07343097776174545, 0.07858540117740631, 0.06889194995164871, 0.05806347727775574, 0.06160524860024452, 0.06426975876092911, 0.06375650316476822, 0.05127176642417908, 0.052760977298021317, 0.060125406831502914, 0.059372447431087494, 0.055980123579502106, 0.05823488533496857, 0.06158577650785446, 0.06649190932512283, 0.060052838176488876, 0.06648772954940796, 0.058435216546058655, 0.0624084398150444, 0.05982623249292374, 0.0688338652253151, 0.056699495762586594, 0.060506246984004974, 0.0610368587076664, 0.05663282796740532, 0.05549633875489235, 0.052887074649333954, 0.05851944163441658, 0.059453334659338, 0.05368904024362564, 0.056335046887397766, 0.07719141244888306, 0.062227215617895126, 0.057563669979572296, 0.0746191218495369, 0.05888864025473595, 0.057501889765262604, 0.06214924529194832, 0.06011208891868591, 0.05073302239179611, 0.056265346705913544, 0.05431075021624565, 0.062130823731422424, 0.05780550464987755, 0.0558902733027935, 0.05914817750453949, 0.05870233476161957, 0.06495003402233124, 0.05804824456572533, 0.05862532556056976, 0.05849318951368332, 0.06464510411024094, 0.06622494757175446, 0.06891430914402008, 0.05913107469677925, 0.05567300319671631, 0.06180806830525398, 0.057774368673563004, 0.05913512781262398, 0.05451099947094917, 0.06693051010370255, 0.05900493264198303, 0.05945005267858505, 0.06607519835233688, 0.0575297512114048, 0.057839348912239075, 0.056518785655498505, 0.05733390524983406, 0.06729862093925476, 0.0515228807926178, 0.05567924305796623, 0.058318767696619034, 0.057064954191446304, 0.05722060799598694, 0.05317215994000435, 0.05275827646255493, 0.05987263470888138, 0.05855043977499008, 0.05029836669564247, 0.054195377975702286, 0.05771744251251221, 0.055123843252658844, 0.054903410375118256, 0.06400538980960846, 0.05510370805859566, 0.060207709670066833, 0.054313234984874725, 0.05728907138109207, 0.05911531299352646, 0.05250866711139679, 0.059937961399555206, 0.07039296627044678, 0.05721312016248703, 0.05631258711218834, 0.06309974193572998, 0.05660725384950638, 0.053073614835739136, 0.055371593683958054, 0.0569196455180645, 0.05441905930638313, 0.05512251332402229, 0.05454867333173752, 0.05619946867227554, 0.05427459999918938, 0.054911550134420395, 0.06024499610066414, 0.052062276750802994, 0.06259912252426147, 0.0532006174325943, 0.06545398384332657, 0.050023797899484634, 0.05024505779147148, 0.06645224988460541, 0.05351093411445618, 0.0531359426677227, 0.05681744962930679, 0.06958722323179245, 0.05037608742713928, 0.05199076980352402, 0.0664641335606575, 0.05646217241883278, 0.06124304234981537, 0.04963425546884537, 0.04579861834645271, 0.050292305648326874, 0.055053453892469406, 0.0569521002471447, 0.06319080293178558, 0.05410784110426903, 0.05596458911895752, 0.05592740327119827, 0.055833108723163605, 0.05173913389444351, 0.05038248002529144, 0.05040164291858673, 0.0523650124669075, 0.05510345473885536, 0.04896165430545807, 0.04608625918626785, 0.048566754907369614, 0.05346016213297844, 0.05288945883512497, 0.05588827654719353, 0.04721630737185478, 0.050384100526571274, 0.04990426078438759, 0.05125298351049423, 0.05146481469273567, 0.049866944551467896, 0.048638034611940384, 0.050483085215091705, 0.048260800540447235, 0.05478666350245476, 0.046335622668266296, 0.05062323808670044, 0.05215272307395935, 0.04973449185490608, 0.05964750424027443, 0.04645844176411629, 0.05513325333595276, 0.06364531069993973, 0.05412065610289574, 0.07047533243894577, 0.05059086158871651, 0.049250513315200806, 0.04512267932295799, 0.05432812497019768, 0.04567771032452583, 0.05120624229311943, 0.05414753407239914, 0.043865133076906204, 0.047760169953107834, 0.04441891983151436, 0.047586213797330856, 0.04802173748612404, 0.05023554712533951, 0.04991796612739563, 0.0563102662563324, 0.05075367912650108, 0.05781295895576477, 0.056652218103408813, 0.051607757806777954, 0.06067487597465515, 0.047926243394613266, 0.04581400007009506, 0.04459033161401749, 0.044094979763031006, 0.048143159598112106, 0.053145211189985275, 0.0513586588203907, 0.04745316132903099, 0.046510376036167145, 0.04569878429174423, 0.048132747411727905, 0.045750513672828674, 0.05251779779791832, 0.04307392239570618, 0.06226136535406113, 0.047212690114974976, 0.047101136296987534, 0.047543156892061234, 0.04862423986196518, 0.054360948503017426, 0.04742885380983353, 0.054783374071121216, 0.04896870627999306, 0.050404224544763565, 0.04701986908912659, 0.05072413757443428, 0.04758809506893158, 0.0567917563021183, 0.047417208552360535, 0.04586237296462059, 0.046189166605472565, 0.052508823573589325, 0.041635267436504364, 0.047265466302633286, 0.047398995608091354, 0.05025188624858856, 0.04375944659113884, 0.05722363293170929, 0.05065125972032547, 0.04794967174530029, 0.04493886977434158, 0.047737546265125275, 0.0508839450776577, 0.04254999756813049, 0.04441506788134575, 0.0458810031414032, 0.05413201451301575, 0.04625323414802551, 0.050721585750579834, 0.0408184751868248, 0.04628657549619675, 0.045437268912792206, 0.040253277868032455, 0.06194194778800011, 0.0554296150803566, 0.04572649300098419, 0.047722332179546356, 0.04343637824058533, 0.04461284354329109, 0.04145419970154762, 0.04144520312547684, 0.04658892750740051, 0.0488801971077919, 0.04320297762751579, 0.0477277897298336, 0.04629435017704964, 0.04559377580881119, 0.046261318027973175, 0.051829032599925995, 0.04520886763930321, 0.04799816012382507, 0.0476677268743515, 0.045035913586616516, 0.048662927001714706, 0.04692200943827629, 0.04354217275977135, 0.0477893240749836, 0.04200318455696106, 0.05014238506555557, 0.04464200139045715, 0.04033683240413666, 0.04401214420795441, 0.04264237359166145, 0.045949045568704605, 0.04675297066569328, 0.047775283455848694, 0.04671873524785042, 0.042794354259967804, 0.04251174256205559, 0.04549748823046684, 0.038654033094644547, 0.04287265986204147, 0.0448494590818882, 0.0403994582593441, 0.04284001514315605, 0.044786617159843445, 0.04362744837999344, 0.04522958770394325, 0.0468575656414032, 0.04054643586277962, 0.040563736110925674, 0.050948578864336014]}],\n",
              "                        {\"height\": 500, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 700, \"xaxis\": {\"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"title\": {\"text\": \"Loss\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('edd2993a-a373-4f42-baec-b5c476612231');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.0285 - mae: 2.3189\n",
            "MSE на тестовых данных:  0.02846105583012104\n",
            "MAE на тестовых данных:  2.3188869953155518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bWivV055yJH",
        "outputId": "5e81ae1b-88af-4cb6-c808-3748932ecb4b"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([23.6, 32.4, 13.6, 22.8, 16.1, 20. , 17.8, 14. , 19.6, 16.8, 21.5,\n",
              "       18.9,  7. , 21.2, 18.5, 29.8, 18.8, 10.2, 50. , 14.1, 25.2, 29.1,\n",
              "       12.7, 22.4, 14.2, 13.8, 20.3, 14.9, 21.7, 18.3, 23.1, 23.8, 15. ,\n",
              "       20.8, 19.1, 19.4, 34.7, 19.5, 24.4, 23.4, 19.7, 28.2, 50. , 17.4,\n",
              "       22.6, 15.1, 13.1, 24.2, 19.9, 24. , 18.9, 35.4, 15.2, 26.5, 43.5,\n",
              "       21.2, 18.4, 28.5, 23.9, 18.5, 25. , 35.4, 31.5, 20.2, 24.1, 20. ,\n",
              "       13.1, 24.8, 30.8, 12.7, 20. , 23.7, 10.8, 20.6, 20.8,  5. , 20.1,\n",
              "       48.5, 10.9,  7. , 20.9, 17.2, 20.9,  9.7, 19.4, 29. , 16.4, 25. ,\n",
              "       25. , 17.1, 23.2, 10.4, 19.6, 17.2, 27.5, 23. , 50. , 17.9,  9.6,\n",
              "       17.2, 22.5, 21.4, 12. , 19.9, 19.4, 13.4, 18.2, 24.6, 21.1, 24.7,\n",
              "        8.7, 27.5, 20.7, 36.2, 31.6, 11.7, 39.8, 13.9, 21.8, 23.7, 17.6,\n",
              "       24.4,  8.8, 19.2, 25.3, 20.4, 23.1, 37.9, 15.6, 45.4, 15.7, 22.6,\n",
              "       14.5, 18.7, 17.8, 16.1, 20.6, 31.6, 29.1, 15.6, 17.5, 22.5, 19.4,\n",
              "       19.3,  8.5, 20.6, 17. , 17.1, 14.5, 50. , 14.3, 12.6, 28.7, 21.2,\n",
              "       19.3, 23.1, 19.1, 25. , 33.4,  5. , 29.6, 18.7, 21.7, 23.1, 22.8,\n",
              "       21. , 48.8])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKTPVJ_L5yJH",
        "outputId": "dd94a665-1f7b-4b6d-b2ed-1c2b794f0eaf"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.41915  ],\n",
              "       [31.720438 ],\n",
              "       [13.114435 ],\n",
              "       [23.124352 ],\n",
              "       [14.055444 ],\n",
              "       [20.181738 ],\n",
              "       [17.633347 ],\n",
              "       [14.07095  ],\n",
              "       [22.689331 ],\n",
              "       [18.888199 ],\n",
              "       [19.722569 ],\n",
              "       [18.018784 ],\n",
              "       [ 8.275054 ],\n",
              "       [20.068077 ],\n",
              "       [18.657694 ],\n",
              "       [23.049606 ],\n",
              "       [19.246357 ],\n",
              "       [ 9.88753  ],\n",
              "       [43.013813 ],\n",
              "       [11.99634  ],\n",
              "       [23.74474  ],\n",
              "       [25.25003  ],\n",
              "       [14.42342  ],\n",
              "       [21.563934 ],\n",
              "       [16.526196 ],\n",
              "       [15.659239 ],\n",
              "       [20.68753  ],\n",
              "       [10.775575 ],\n",
              "       [18.946312 ],\n",
              "       [18.446716 ],\n",
              "       [19.442429 ],\n",
              "       [22.852234 ],\n",
              "       [19.458496 ],\n",
              "       [23.572289 ],\n",
              "       [12.491953 ],\n",
              "       [15.637371 ],\n",
              "       [29.755348 ],\n",
              "       [19.94889  ],\n",
              "       [20.45739  ],\n",
              "       [23.610598 ],\n",
              "       [16.543102 ],\n",
              "       [28.565825 ],\n",
              "       [44.74477  ],\n",
              "       [18.642258 ],\n",
              "       [22.530983 ],\n",
              "       [14.98048  ],\n",
              "       [15.642636 ],\n",
              "       [25.042206 ],\n",
              "       [16.397945 ],\n",
              "       [24.108727 ],\n",
              "       [19.11203  ],\n",
              "       [32.11286  ],\n",
              "       [16.34437  ],\n",
              "       [24.219742 ],\n",
              "       [41.84434  ],\n",
              "       [23.303818 ],\n",
              "       [14.735199 ],\n",
              "       [31.469227 ],\n",
              "       [22.302313 ],\n",
              "       [16.658325 ],\n",
              "       [23.01482  ],\n",
              "       [33.968204 ],\n",
              "       [32.36666  ],\n",
              "       [17.68911  ],\n",
              "       [21.664864 ],\n",
              "       [16.911022 ],\n",
              "       [14.515743 ],\n",
              "       [22.769567 ],\n",
              "       [27.206303 ],\n",
              "       [11.417925 ],\n",
              "       [20.073479 ],\n",
              "       [28.166134 ],\n",
              "       [ 9.511871 ],\n",
              "       [19.288124 ],\n",
              "       [21.319166 ],\n",
              "       [ 4.593726 ],\n",
              "       [19.120384 ],\n",
              "       [43.4273   ],\n",
              "       [10.875272 ],\n",
              "       [11.379335 ],\n",
              "       [19.943428 ],\n",
              "       [10.609758 ],\n",
              "       [20.00237  ],\n",
              "       [10.816693 ],\n",
              "       [19.778673 ],\n",
              "       [27.205143 ],\n",
              "       [15.958986 ],\n",
              "       [23.617651 ],\n",
              "       [24.33237  ],\n",
              "       [17.856194 ],\n",
              "       [21.795628 ],\n",
              "       [ 8.112575 ],\n",
              "       [18.184803 ],\n",
              "       [17.54293  ],\n",
              "       [23.133823 ],\n",
              "       [18.771149 ],\n",
              "       [26.402536 ],\n",
              "       [ 9.299728 ],\n",
              "       [10.847036 ],\n",
              "       [ 9.991507 ],\n",
              "       [20.566526 ],\n",
              "       [22.000925 ],\n",
              "       [ 9.568938 ],\n",
              "       [18.992174 ],\n",
              "       [20.686695 ],\n",
              "       [ 8.629223 ],\n",
              "       [18.295898 ],\n",
              "       [24.863352 ],\n",
              "       [20.769434 ],\n",
              "       [22.273758 ],\n",
              "       [ 8.009229 ],\n",
              "       [13.0716095],\n",
              "       [21.689915 ],\n",
              "       [22.550488 ],\n",
              "       [34.14607  ],\n",
              "       [13.924936 ],\n",
              "       [35.69327  ],\n",
              "       [15.047452 ],\n",
              "       [19.640812 ],\n",
              "       [25.80075  ],\n",
              "       [17.43231  ],\n",
              "       [24.585785 ],\n",
              "       [ 8.585602 ],\n",
              "       [20.1384   ],\n",
              "       [23.576117 ],\n",
              "       [20.920141 ],\n",
              "       [23.24289  ],\n",
              "       [30.552895 ],\n",
              "       [15.1637745],\n",
              "       [40.984707 ],\n",
              "       [16.708479 ],\n",
              "       [22.834038 ],\n",
              "       [17.053839 ],\n",
              "       [18.330942 ],\n",
              "       [13.324731 ],\n",
              "       [18.440771 ],\n",
              "       [21.271011 ],\n",
              "       [30.430202 ],\n",
              "       [26.898323 ],\n",
              "       [16.44565  ],\n",
              "       [17.194633 ],\n",
              "       [24.932318 ],\n",
              "       [20.15915  ],\n",
              "       [17.133862 ],\n",
              "       [ 5.982503 ],\n",
              "       [21.395697 ],\n",
              "       [15.967825 ],\n",
              "       [11.260855 ],\n",
              "       [15.586185 ],\n",
              "       [45.25506  ],\n",
              "       [14.243425 ],\n",
              "       [13.495886 ],\n",
              "       [22.759165 ],\n",
              "       [20.549726 ],\n",
              "       [20.438457 ],\n",
              "       [20.389313 ],\n",
              "       [10.975636 ],\n",
              "       [25.626274 ],\n",
              "       [28.604214 ],\n",
              "       [ 7.442615 ],\n",
              "       [21.134857 ],\n",
              "       [18.241657 ],\n",
              "       [20.005846 ],\n",
              "       [22.590538 ],\n",
              "       [21.23102  ],\n",
              "       [19.023386 ],\n",
              "       [45.48421  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UghYIzFedv0-"
      },
      "source": [
        "3. Поработайте с документацией TensorFlow 2. Найти 2-3 полезные команды TensorFlow, не разобранные на уроке (полезные для Вас).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9JJmO-cylr0"
      },
      "source": [
        "1. tf.estimator.BaselineClassifier, tf.estimator.BaselineRegressor для быстрого построения базовых\n",
        "\n",
        "2. tf.keras.utils.text_dataset_from_directory собирает датасет из текстовых файлов"
      ]
    }
  ]
}